{
  "MIGRATION-README.html": {
    "href": "MIGRATION-README.html",
    "title": "XMPro Documentation Migration: GitBook to DocFX | XMPro",
    "summary": "XMPro Documentation Migration: GitBook to DocFX This document provides an overview of the migration process from GitBook to DocFX for the XMPro documentation. Migration Overview The XMPro documentation is being migrated from GitBook to DocFX. This migration involves: Setting up the DocFX project structure Migrating the navigation structure Migrating content pages Migrating images and other assets Implementing styling and customization Verifying links and functionality Deploying the migrated documentation Migration Plan The detailed migration plan is available in the migration-plan.md file. This plan outlines the step-by-step process for migrating the documentation, including: Branching strategy Migration steps Content migration guidelines Image migration Link updates Progress tracking Migration Helper Script A PowerShell script (migration-helper.ps1) has been created to assist with the migration process. This script helps automate the following tasks: Creating the directory structure Converting GitBook Markdown to DocFX Markdown Migrating images Generating TOC files Using the Migration Helper Script To use the migration helper script, follow these steps: Open a PowerShell terminal Navigate to the docs-docfx directory Run the script with the appropriate parameters .\\migration-helper.ps1 -GitBookPath \"C:\\path\\to\\gitbook\" -DocFXPath \"C:\\path\\to\\docfx\" Parameters -GitBookPath: The path to the GitBook repository -DocFXPath: The path to the DocFX repository -Section: (Optional) The section to migrate (e.g., \"getting-started\", \"concepts\") -CreateStructure: (Optional) Create the directory structure -MigrateContent: (Optional) Migrate content -MigrateImages: (Optional) Migrate images -GenerateToc: (Optional) Generate TOC files Examples Migrate everything: .\\migration-helper.ps1 -GitBookPath \"C:\\Work\\Git\\public-docs-pages\\docs-gitbook\" -DocFXPath \"C:\\Work\\Git\\public-docs-pages\\docs-docfx\" Migrate a specific section: .\\migration-helper.ps1 -GitBookPath \"C:\\Work\\Git\\public-docs-pages\\docs-gitbook\" -DocFXPath \"C:\\Work\\Git\\public-docs-pages\\docs-docfx\" -Section \"getting-started\" Create the directory structure only: .\\migration-helper.ps1 -GitBookPath \"C:\\Work\\Git\\public-docs-pages\\docs-gitbook\" -DocFXPath \"C:\\Work\\Git\\public-docs-pages\\docs-docfx\" -CreateStructure Migration Progress Tracking The migration progress is tracked in the following way: Each step in the migration plan is done on a separate feature branch Each branch is reviewed and merged through a pull request The progress is tracked in the migration plan document Branching Strategy The branching strategy for the migration is as follows: Create a feature branch for each step in the migration plan Implement the step on the feature branch Test the changes locally Create a pull request for review Merge the pull request to the main branch The branch naming convention is: migrate/[section-name]/[specific-task] For example: migrate/navigation/main-toc migrate/content/getting-started migrate/assets/images Creating Feature Branches For each step in the migration process, create a new feature branch from the main branch: # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/[section-name]/[specific-task] Completing a Migration Step After completing a migration step: # Commit changes git add . git commit -m \"Description of changes\" git push -u origin migrate/[section-name]/[specific-task] # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step The migration plan includes specific git commands for each step to ensure consistency throughout the migration process. Testing the Migration To test the migration, follow these steps: Build the DocFX project: cd docs-docfx docfx build Serve the DocFX project locally: cd docs-docfx docfx serve _site Open a browser and navigate to http://localhost:8080 Verify that the documentation displays correctly Handling DocFX Build Warnings During the migration process, you will encounter various warnings when building the DocFX project. These warnings are normal and expected, especially during the early stages of migration when not all content has been migrated yet. For detailed information on how to handle these warnings, refer to the handling-docfx-warnings.md document. This document explains: Types of warnings you will encounter Why these warnings occur How to handle these warnings during the migration process Strategies for addressing specific warning types Using the migration helper script to resolve warnings Final cleanup process to address remaining warnings It's important to note that you can safely ignore most warnings during the migration process, as they will be resolved as you progress through the migration steps. However, it's good practice to keep track of warnings and address them incrementally as you migrate each section. Deployment A GitHub Actions workflow has been set up to automatically deploy the documentation to GitHub Pages whenever changes are merged into the main branch. This ensures that each migration step is immediately visible on the public documentation site once it's completed and merged. GitHub Actions Workflow The deployment workflow is defined in .github/workflows/deploy-docs.yml and performs the following steps: Checks out the repository Sets up .NET Installs DocFX Builds the DocFX documentation Deploys the built site to the gh-pages branch Deployment Process The deployment process is as follows: Complete a migration step on a feature branch Test the changes locally Create a pull request for the feature branch Review and merge the pull request into the main branch GitHub Actions automatically builds and deploys the documentation to GitHub Pages Verify the changes on the live site Manual Deployment If needed, you can also trigger a manual deployment by: Going to the GitHub repository Clicking on the \"Actions\" tab Selecting the \"Deploy DocFX to GitHub Pages\" workflow Clicking on \"Run workflow\" Conclusion This migration process is designed to be iterative and incremental. Each step is completed and verified before moving on to the next step. This approach minimizes the risk of issues and ensures that the migration is done correctly. If you have any questions or issues with the migration process, please contact the documentation team."
  },
  "cache-busting-readme.html": {
    "href": "cache-busting-readme.html",
    "title": "Cache Busting Solution for GitHub Pages | XMPro",
    "summary": "Cache Busting Solution for GitHub Pages This document explains the cache busting solution implemented for the XMPro documentation site hosted on GitHub Pages. Problem GitHub Pages serves static content with default cache headers that can cause browsers to cache HTML pages and other resources. This can lead to users not seeing the latest changes unless they perform a hard refresh or open the site in a private/incognito window. Solution The solution implements multiple layers of cache busting to ensure users always get the latest content: 1. Cache Control Meta Tags The HTML pages include the following meta tags to prevent caching: <meta http-equiv=\"Cache-Control\" content=\"no-cache, no-store, must-revalidate\"> <meta http-equiv=\"Pragma\" content=\"no-cache\"> <meta http-equiv=\"Expires\" content=\"0\"> 2. Service Worker A service worker (service-worker.js) is implemented to control caching behavior: HTML files are always fetched from the network first, with cache as a fallback Other resources use a cache-first strategy for better performance The service worker is updated with each build, forcing a refresh of the cache The service worker uses skipWaiting() and clients.claim() to take control immediately 3. Version Tracking A version tracking system is implemented to detect when new content is available: version.js contains a timestamp that is updated with each build version-check.js periodically checks for a new version and reloads the page if detected Implementation Details Custom DocFX Template A custom DocFX template is used to add the cache control meta tags and scripts to the HTML pages. GitHub Workflow The GitHub workflow has been updated to: Generate a new timestamp for each build Update the version.js file with the new timestamp Build the site with DocFX Deploy the site to GitHub Pages Files Added/Modified templates/modern/partials/head.tmpl.partial - Added cache control meta tags and scripts service-worker.js - Service worker implementation for cache control register-sw.js - Script to register the service worker version.js - Contains the build timestamp version-check.js - Checks for new versions and reloads the page docfx.json - Updated to include the new files .github/workflows/docfx.yml - Updated to generate a new timestamp with each build Testing To test if the cache busting is working: Visit the site in a normal browser window Make changes to the site and deploy them Wait for the deployment to complete The page should automatically reload with the new content within 5 minutes Alternatively, you can manually refresh the page to see the changes immediately Troubleshooting If you're still experiencing caching issues: Open the browser's developer tools Go to the Application tab Check the Service Worker section to ensure it's active Check the Cache Storage section to see what's being cached Try clearing the browser cache manually"
  },
  "docs/concepts/agent/index.html": {
    "href": "docs/concepts/agent/index.html",
    "title": "Agent | XMPro",
    "summary": "Agent An Agent is a reusable object which forms the building block of a Data Stream. When a number of Agents are connected together, a Data Stream is formed. Each Agent is designed to perform a specific function in the stream. For example, they can be used to retrieve data from a database in real-time, display data, filter, sort the data, or save the data somewhere else, depending on the function of that individual Agent. Agents are needed to connect to specific systems. Since Agents are individual components, new Agents can also be added and integrated into the Data Stream to complete a specific functionality. Video Presentation Discussing Agents and Collections Each Agent consists of code, settings, and other properties that are packaged into a file that can be uploaded to Data Stream Designer. XMPro has a library of Agents available to use. To acquire any of these Agents, please contact your XMPro sales representative or write to us at support@xmpro.com. Alternatively, since Agents can be written by anyone that has some knowledge of programming and has access to the required technologies, you can write your own Agent by following these instructions. Categories In Data Steam Designer, Agents are divided into different categories, depending on the overall function they perform. There are six different categories available: Action Agents, Context Providers, Listeners, Transformations, AI & Machine Learning, Recommendations, and Functions. To be able to distinguish them properly, they have been tagged with a certain color as well as an abbreviation. These categories are separate from the App and Data Stream Categories. Action Agents An Action Agent is an Agent that consumes events in a stream and then performs internal or external (third-party) actions, e.g. sending notifications or performing data warehouse updates. Action Agents output a response after each event has been processed. For example, the Azure SQL Action Agent writes data to an Azure SQL database. Context Providers Context providers are Agents that provide context to a stream by consuming reference or static data and making it available. For example, the SQL Server Context Provider provides static data to the Data Stream by reading the data in a database table and sending it to the next Agent. Listeners Listeners are Agents that listen for data or events from sensors and third-party systems. For example, the MQTT Listener listens for data from sensors as it is posted to MQTT. Transformations Transformation Agents alter the shape or form of data. For example, the Join Transformation joins data it receives from two separate data sources. AI & Machine Learning AI & Machine Learning Agents allow you to run advanced AI to transform the data. For example, Azure ML, IBM Watson, and Jupyter Notebook. Recommendations Recommendation Agents are related to Recommendations and let you complete actions such as running recommendations, updating recommendations, and more. Functions Functions perform specific mathematical or statistical operations on data. For example, the FFT Function performs forward FFT calculations on the data it receives. Settings An Agent consists of code and user settings. The code defines the actions an Agent performs in any Data Stream. The settings are the input for the code that executes, provided by the user when adding the Agent to a Data Stream, such as authentication credentials. For example, consider the SQL Server Writer Agent. The function this Agent performs in a Data Stream is to take the data it receives and write it to a table in a database. The settings a user must define for the Agent so it can do that are as follows: Name of the SQL Server instance SQL Server username Whether SQL Server authentication should be used or not SQL Server password Database to which the data should be written Whether a new table should be created or not Table to which data should be written - if the user wishes to use an existing table Name of the table that should be created if the user wants to write the data to a new table If database triggers should be fired when a record is inserted Endpoints Endpoints provide entry and exit points to the Agent. The input endpoint allows the Agent to receive data from another Agent, whereas the output endpoint enables the Agent to pass data to another Agent. They are represented on the Data Stream canvas as green rectangles. The error endpoint allows an Agent to send any error data further along a part of the stream, designed to handle data records or events that do not meet certain requirements. It is represented on the Data Stream canvas as a red rectangle. Note Image placeholder: Fig 1. Data Stream Canvas and Agent's User Settings Note Image placeholder: Fig 2. Agent properties Finding Agents The search bar can be used to find any specific Agents that you may be looking for. There is a dropdown option where you can specify to search through everything in Data Stream Designer, or only for Agents. Note Image placeholder: Fig 3. Searching for an Agent Versions Agents can keep track of their different versions. Versions of an Agent can be copied, and changes made to it can be created as a new version without affecting previous versions. See the Version article for more details on versions. Publish and Unpublish Data Streams On the Agents page, there will be a number next to the version if the agent has been used in a Data Stream. Click the number to view a list of all Data Streams that are using that Agent version. Here you can directly unpublish or publish a Data Stream. As an Admin, this is useful if you need to unpublish a Data Stream and you don't have access to it. See the How to Admin Unpublish Override article for more details. Note Image placeholder: Fig 4. Data Stream Toolbox Interface Actions on the Agent Action Description Add Adds a new Agent. Select Selects multiple Agents. Delete Deletes the Agent. Save Saves any changes made to the Agent up to this point. Discard Discards any changes made to the Agent up to this point. Delete Versions Deletes selected versions of the Agent. Further Reading Agent FAQs How to Create and Manage Agents How to Run an Integrity Check How to Upgrade a Stream Object Version How to Use Error Endpoints Virtual vs Non-Virtual Agents"
  },
  "docs/concepts/agent/virtual-vs-non-virtual-agents.html": {
    "href": "docs/concepts/agent/virtual-vs-non-virtual-agents.html",
    "title": "Virtual vs Non-Virtual Agents | XMPro",
    "summary": "Virtual vs Non-Virtual Agents There can be two types of Agents in Data Streams; Virtual and Non-Virtual Agents. When packaging an Agent using the Stream Integration Manager, it is important to specify if an Agent is Virtual by making sure that the Virtual checkbox is correctly ticked. Virtual Agents A Virtual Agent is an Agent that is not bound to a certain environment to be able to function, for example, the Azure SQL Listener is an Agent which can be configured anywhere as it will always have access to the globally available Azure SQL Server, which it needs to integrate with. Non-Virtual Agents An Agent can be classified as Non-Virtual if it relies on a specific environment to function. Non-Virtual Agents need to interact with a system that is only available in a specific environment, for example, the SQL Server Listener. The SQL Server Listener is an Agent that can only be configured while it is on the same local area network as the SQL Server instance it needs to connect to. Note Image placeholder: Virtual vs Non-Virtual Agents As shown in the diagram above, even though both Virtual and Non-Virtual Agents ultimately run on the Stream Host, there is a considerable difference in how they are handled at design time. A Virtual Agent can be configured even if no Stream Host is online, but this is not possible for a Non-Virtual one. Virtual Agents are also very fast as the engine doesn't have to go all the way to the Stream Host to configure them and this results in a smoother user experience. Note Virtual Agents can be configured even if there is no Stream Host online, but Non-Virtual Agents require a Stream Host to be online."
  },
  "docs/concepts/data-stream/index.html": {
    "href": "docs/concepts/data-stream/index.html",
    "title": "Data Stream | XMPro",
    "summary": "Data Stream A Data Stream is a visual representation of a flow of data. It is created through the Data Stream Designer and consists of Stream Objects that ingest, transform, analyze, and act on data. Overview Data Streams are the backbone of real-time data processing in XMPro. They allow you to: Ingest data from various sources Transform and enrich data Analyze data for patterns and anomalies Take actions based on the data Data Streams are designed to be: Visual and intuitive Real-time Scalable Flexible Components of a Data Stream A Data Stream consists of the following components: Stream Objects Stream Objects are the building blocks of a Data Stream. They are instances of Agents that perform specific functions in the data flow. Stream Objects are connected together to form a pipeline of data processing. Connections Connections define how data flows between Stream Objects. They are represented as arrows in the Data Stream Designer. Data Data flows through the Stream Objects and is transformed, analyzed, and acted upon as it moves through the Data Stream. Types of Data Streams There are two types of Data Streams: Streaming Streaming Data Streams run continuously, processing data as it arrives. They are used for real-time monitoring and alerting. Recurrent Recurrent Data Streams run on a schedule, processing data in batches. They are used for periodic reporting and analysis. Related Concepts Stream Object Configuration Verifying Stream Integrity Running Data Streams Timeline"
  },
  "docs/concepts/data-stream/stream-object-configuration.html": {
    "href": "docs/concepts/data-stream/stream-object-configuration.html",
    "title": "Stream Object Configuration | XMPro",
    "summary": "Stream Object Configuration Stream Objects are the building blocks of a Data Stream. Each Stream Object is an instance of an Agent that performs a specific function in the data flow. This page explains how to configure Stream Objects in a Data Stream. Overview When you add a Stream Object to a Data Stream, you need to configure it to perform the specific function you want. The configuration options depend on the type of Agent the Stream Object is based on. Configuration Process To configure a Stream Object: Double-click on the Stream Object in the Data Stream Designer, or select the Stream Object and click the \"Configure\" button in the toolbar. The configuration panel for the Stream Object will open, showing the available configuration options. Configure the Stream Object according to your requirements. Click \"Apply\" to save the configuration. Common Configuration Options While each Agent type has its own specific configuration options, there are some common options that apply to most Stream Objects: Name The name of the Stream Object. This is displayed on the Stream Object in the Data Stream Designer. Description A description of the Stream Object. This is useful for documenting the purpose of the Stream Object. Input Mappings Input Mappings define how data from the previous Stream Object is mapped to the inputs of the current Stream Object. This is particularly important when the output schema of the previous Stream Object doesn't match the input schema expected by the current Stream Object. Error Handling Error Handling options define what happens when an error occurs in the Stream Object. Options typically include: Continue: Continue processing data even if an error occurs. Stop: Stop processing data if an error occurs. Retry: Retry the operation if an error occurs. Agent-Specific Configuration Each Agent type has its own specific configuration options. For example: Listener Agents Listener Agents ingest data from external sources. Configuration options typically include: Connection details: How to connect to the data source. Data format: The format of the data being ingested. Polling interval: How often to check for new data (for polling-based Listeners). Transformation Agents Transformation Agents transform data as it flows through the Data Stream. Configuration options typically include: Transformation logic: How to transform the data. Output schema: The schema of the transformed data. Action Agents Action Agents perform actions based on the data. Configuration options typically include: Action details: What action to perform. Trigger conditions: When to perform the action. Best Practices When configuring Stream Objects, consider the following best practices: Use meaningful names: Give your Stream Objects meaningful names that describe their purpose. Document your configuration: Use the description field to document the purpose and configuration of the Stream Object. Test your configuration: Use the Live View feature to test your configuration with sample data. Keep it simple: Break complex transformations into multiple simple transformations for better maintainability. Related Concepts Data Stream Verifying Stream Integrity Running Data Streams Timeline"
  },
  "docs/concepts/index.html": {
    "href": "docs/concepts/index.html",
    "title": "Concepts | XMPro",
    "summary": "Concepts This section provides detailed explanations of the core concepts in the XMPro platform. Understanding these concepts will help you build effective real-time applications. XMPro AI XMPro AI provides AI capabilities to enhance your applications, including the XMPro Notebook for data analysis and machine learning. Data Stream Data Streams are the backbone of real-time data processing in XMPro. They allow you to ingest, transform, analyze, and act on data from various sources. Collection and Stream Host Collections and Stream Hosts manage the execution of Data Streams and provide scalability and reliability. Agent Agents are the building blocks of Data Streams, providing specific functionality for data ingestion, transformation, analysis, and actions. Application Applications provide the user interface for your real-time solutions, allowing users to visualize data and take actions. Recommendation Recommendations enable you to create rules that trigger alerts and actions based on conditions in your data. Connector Connectors provide integration with external systems and data sources. Landing Pages & Favorites Landing Pages & Favorites help users quickly access the information and applications they need. Version Versioning allows you to manage changes to your Data Streams, Applications, and Recommendations over time. Manage Access Access Management controls who can view and edit your Data Streams, Applications, and Recommendations. Category Categories help organize your Data Streams, Applications, and Recommendations. Variable Variables store configuration values that can be reused across your Data Streams, Applications, and Recommendations. Insights Insights provide analytics and monitoring capabilities for your Data Streams and Applications."
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Getting Started | XMPro",
    "summary": "Getting Started"
  },
  "docs/getting-started/browser-requirements.html": {
    "href": "docs/getting-started/browser-requirements.html",
    "title": "Browser Requirements | XMPro",
    "summary": "Browser Requirements Supported Browsers The XMPro platform can be run on a variety of browsers and operating systems. The latest two major releases of the following browsers are supported on the indicated operating systems: Browser Windows macOS iOS Android Google Chrome ✓ ✓ ✓ ✓ Apple Safari ✗ ✓ ✓ ✗ Microsoft Edge ✓ ✓ ✗ ✗ Mozilla Firefox ✓ ✓ ✗ ✗ Opera ✓ ✓ ✗ ✗ Supported Operating Systems The following operating systems are supported for browsers running the XMPro platform: Operating System Supported versions Windows Windows 10 or later macOS 10.13 or later iOS iOS 10 or later Android 5 or later Third-Party Cookies The XMPro Platform requires third-party cookies on web browsers to be allowed/enabled for it to function properly. Follow the steps below to enable cookies on the different browsers. Note Enabling third-party cookies is essential for the XMPro platform to function correctly. Without this setting, you may experience issues with authentication and certain features. Google Chrome On your computer, open Chrome. At the top right, click More, then Settings. Under \"Privacy and security,\" click Site settings. Click Cookies. Next to \"Blocked,\" turn on the switch to turn on cookies. For more information, you can visit the Official Google Chrome Documentation. Microsoft Edge Open Microsoft Edge, select Menu (3 dots icon on the top right corner of the browser) > Settings > Site permissions > Cookies and site data Turn on \"Allow sites to save and read cookie data (recommended)\" to unblock cookies Turn on \"Block third-party cookies\" or add desired sites in the \"Block\" section to block the cookies. For more information, you can visit the Official Microsoft Documentation. Apple Safari In the Safari app on your Mac, choose Safari > Preferences Click Privacy Unselect \"Block all cookies\". For more information, you can visit the Official Apple Documentation."
  },
  "docs/getting-started/browser-requirements.sample.html": {
    "href": "docs/getting-started/browser-requirements.sample.html",
    "title": "Browser Requirements | XMPro",
    "summary": "Browser Requirements This sample page demonstrates how to format content in DocFX markdown. Supported Browsers The XMPro platform can be run on a variety of browsers and operating systems. The latest two major releases of the following browsers are supported on the indicated operating systems: Browser Windows macOS iOS Android Google Chrome ✓ ✓ ✓ ✓ Apple Safari ✗ ✓ ✓ ✗ Microsoft Edge ✓ ✓ ✗ ✗ Mozilla Firefox ✓ ✓ ✗ ✗ Opera ✓ ✓ ✗ ✗ Alerts DocFX supports various types of alerts: Note This is a note alert. Use it for general information. Tip This is a tip alert. Use it for helpful tips. Warning This is a warning alert. Use it for important warnings. Caution This is a caution alert. Use it for critical information. Important This is an important alert. Use it for essential information. Code Blocks DocFX supports code blocks with syntax highlighting: public class Program { public static void Main(string[] args) { Console.WriteLine(\"Hello, World!\"); } } function sayHello() { console.log(\"Hello, World!\"); } { \"name\": \"John Doe\", \"age\": 30, \"isActive\": true } Tabs DocFX supports tabs: Windows macOS Linux This content is for Windows users. This content is for macOS users. This content is for Linux users. Images DocFX supports images: Links DocFX supports various types of links: Internal link to Introduction Internal link to a section External link to XMPro website Link to a section on the same page Lists DocFX supports ordered and unordered lists: Unordered list: Item 1 Item 2 Item 3 Nested item 1 Nested item 2 Ordered list: First item Second item Third item Nested item 1 Nested item 2 Tables DocFX supports tables: Name Description Required id The unique identifier Yes name The display name Yes description The description No type The data type Yes Blockquotes DocFX supports blockquotes: This is a blockquote. It can span multiple lines. Horizontal Rules DocFX supports horizontal rules: Emphasis DocFX supports emphasis: Italic text Bold text Bold and italic text Conclusion This sample page demonstrates the various formatting options available in DocFX markdown. Use this as a reference when migrating content from GitBook to DocFX."
  },
  "docs/getting-started/end-to-end-use-case.html": {
    "href": "docs/getting-started/end-to-end-use-case.html",
    "title": "End-To-End Use Case | XMPro",
    "summary": "End-To-End Use Case Note This Use Case assumes the XMPro platform is installed and configured, or you are using the Free Trial that has everything set up for you. This step-by-step tutorial is meant to be an introduction to using the XMPro platform. Completing it will give you a solid foundation to understand the more advanced concepts and detailed how-to guides. This tutorial will explain how to create and design a Data Stream, configure Stream Objects to ingest, analyze, transform, and perform actions on data. You will also learn how to set up a Recommendation to generate alerts based on rule logic, create and design an App, create Data Sources and Connections, and configure a simple Data Grid and Chart. Warning Please note that the XMPro platform requires third-party cookies to be enabled on your browser. Use Case Let's assume there is a power plant that uses a heat exchanger to keep the turbine cool and at the optimum temperature. The heat exchanger circulates water between the cooling tower and the heat exchanger to dissipate heat. To keep a proper circulation of liquid, there are three pumps [A, B, C] installed. Each Pump has a sensor that provides live data for Flow Rate (L/m) and Temperature (°C) using MQTT. Unless the Pump is under maintenance the Flow Rate should be above 15000 L/m and Water temperature should be below 130°C. Engineers should be alerted if the average flow rate falls below 250 L/s. If the average temperature starts to rise above 130°C then a critical level alert should be raised. Engineers should be provided a view to check the history of pump telemetry, maintenance records, and reservoir level to enable them to take necessary action. 1. Design Data Streams with Real-Time Data Sources [Content for this section would be added during the actual migration] 2. Create Event Rules & Recommendations [Content for this section would be added during the actual migration] 3. Create Event Boards & Apps [Content for this section would be added during the actual migration]"
  },
  "docs/getting-started/free-trial.html": {
    "href": "docs/getting-started/free-trial.html",
    "title": "Free Trial | XMPro",
    "summary": "Free Trial How To Sign Up Are you interested in taking the XMPro Application Development Platform for a test drive? Visit this link to request a 90-day free account with no credit card required to get started. After completing the registration form, you will receive a confirmation email with your login details. What's Included in the Free Trial During the free trial, you will get access to the full suite of XMPro Products along with: Unlimited Data Streams Unlimited Applications Unlimited Recommendations XMPro Notebook Selection of XMPro Agents and Connectors Basic 2GB Azure SQL database for master data storage Please get in touch with support if you require additional Agents and Connectors unavailable in your trial account. Note You will need to upgrade your XMPro Free Account to a paid subscription to continue using the services after your trial period expires. Read the free trial terms and conditions for more details. Explore The Demo Use Case Your free trial account includes a pre-built demo use case, which includes a Data Stream, App and Recommendation focused on solving a specific business problem. In this scenario, a renewable energy company wants to move from a planned maintenance schedule to condition-based maintenance for their assets across multiple plants. There is a Data Stream to: Simulate real-time telemetry data for the assets Combine it with contextual data from a SQL database Check whether the data exceeds certain thresholds Run recommendation rules Publish data to an XMPro App We've also created an App to provide the energy company's engineers with decision support for their new condition-based maintenance program. The App provides them with: A map view of all their assets at their various plants The remaining useful life for assets that require maintenance in the next 14 days Recommendation alerts when specific assets exceed certain thresholds If you drill down into a specific asset, you will see: Live telemetry data such as bearing vibration and temperature for different components Live wind speed and gearbox oil level visualizations Operational safety intelligence information to prevent safety incidents during maintenance The effective utilization score for this specific asset In this scenario, XMPro will generate a recommendation alert when: Gearbox oil viscosity for a wind turbine goes above 75 Oil level reaches a low threshold Next Steps This demo use case demonstrates how you can use the XMPro Platform to build a real-time application in 3 simple steps: Create Data Streams to integrate your data sources & orchestrate the data flow Design visualizations for a real-time view of your operations Create prescriptive recommendations that trigger when critical events happen Once you're done exploring the demo, you can start building your first End-To-End Use Case by following this detailed tutorial."
  },
  "docs/introduction.html": {
    "href": "docs/introduction.html",
    "title": "What is XMPro? | XMPro",
    "summary": "What is XMPro? XMPro's Application Development Platform empowers engineers and subject matter experts to build real-time applications without coding. The platform consists of 3 main software components: XMPro App Designer A visual page designer that enables you to create custom page designs by dragging blocks from the toolbox onto your page, configure their properties and connect to your data sources, all without having to code. XMPro Data Stream Designer A drag-and-drop interface to visually design Data Streams (a streaming data pipeline). Use XMPro Connectors in your Data Streams to bring in real-time data from a variety of sources, add contextual data, apply analytics, and initiate actions based on events in your data. XMPro Notebook Harnessing the power of the Jupyter Notebook, XMPro Notebook provides an intuitive and flexible interface for data analysis, scientific computing, machine learning, and more. Users can write and execute code independently, facilitating step-by-step exploration and experimentation with real-time data. XMPro Connectors XMPro's extensible integration library includes 100+ Connectors for industrial automation solutions, IoT platforms, historians, enterprise applications, AI/ML, and collaboration solutions. Watch The Demo Video Watch the demo video to see XMPro's platform in action How The Documentation Is Organized Getting Started - New here? Sign up for a free trial and get started with the End-To-End Use Case sample project. Resources - A goldmine of general articles, such as release news, a sizing guideline, an icon library, and FAQs to elevate your product experience. Concepts - Get detailed explanations of the platform's essential concepts, like Data Streams, Recommendations, Applications, and Connectors. How-To Guides - Follow step-by-step tutorials to help you create Apps and Data Streams. Blocks - Get detailed descriptions of the components you can use to design your App pages and how to configure them. Administration - Find out how to manage users, licenses, and subscriptions in XMPro. This documentation is only relevant to administrators. Installation - Learn how to Install XMPro in a variety of environments. This documentation is only relevant to administrators. Release Notes - Stay up to date on the latest features and bug fixes. Note Can't find what you're looking for? Search the docs for instant results or contact support. Try searching a phrase - such as a release version \"v4.3.2\" to find pages added for that release. Try asking a question - for best results use a full sentence rather than a phrase. DocFX powers Documentation.xmpro.com. The search functionality is driven by an index which includes all XMPro documentation, video tutorials, blogs, publications, and the website. Note The Beta tag indicates incremental functionality, added to prepare for a future feature."
  },
  "docs/introduction.sample.html": {
    "href": "docs/introduction.sample.html",
    "title": "What is XMPro? | XMPro",
    "summary": "What is XMPro? XMPro's Application Development Platform empowers engineers and subject matter experts to build real-time applications without coding. The platform consists of 3 main software components: XMPro App Designer A visual page designer that enables you to create custom page designs by dragging blocks from the toolbox onto your page, configure their properties and connect to your data sources, all without having to code. XMPro Data Stream Designer A drag-and-drop interface to visually design Data Streams (a streaming data pipeline). Use XMPro Connectors in your Data Streams to bring in real-time data from a variety of sources, add contextual data, apply analytics, and initiate actions based on events in your data. XMPro Notebook Harnessing the power of the Jupyter Notebook, XMPro Notebook provides an intuitive and flexible interface for data analysis, scientific computing, machine learning, and more. Users can write and execute code independently, facilitating step-by-step exploration and experimentation with real-time data. XMPro Connectors XMPro's extensible integration library includes 100+ Connectors for industrial automation solutions, IoT platforms, historians, enterprise applications, AI/ML, and collaboration solutions. Watch The Demo Video Watch the demo video to see XMPro's platform in action How The Documentation Is Organized Getting Started - New here? Sign up for a free trial and get started with the End-To-End Use Case sample project. Resources - A goldmine of general articles, such as release news, a sizing guideline, an icon library, and FAQs to elevate your product experience. Concepts - Get detailed explanations of the platform's essential concepts, like Data Streams, Recommendations, Applications, and Connectors. How-To Guides - Follow step-by-step tutorials to help you create Apps and Data Streams. Blocks - Get detailed descriptions of the components you can use to design your App pages and how to configure them. Administration - Find out how to manage users, licenses, and subscriptions in XMPro. This documentation is only relevant to administrators. Installation - Learn how to Install XMPro in a variety of environments. This documentation is only relevant to administrators. Release Notes - Stay up to date on the latest features and bug fixes. Note Can't find what you're looking for? Search the docs for instant results or contact support. Try searching a phrase - such as a release version \"v4.3.2\" to find pages added for that release. Try asking a question - for best results use a full sentence rather than a phrase. DocFX powers Documentation.xmpro.com. The search functionality is driven by an index which includes all XMPro documentation, video tutorials, blogs, publications, and the website. Note The Beta tag indicates incremental functionality, added to prepare for a future feature."
  },
  "handling-docfx-warnings.html": {
    "href": "handling-docfx-warnings.html",
    "title": "Handling DocFX Build Warnings | XMPro",
    "summary": "Handling DocFX Build Warnings During the migration process from GitBook to DocFX, you will encounter various warnings when building the DocFX project. This document explains these warnings and how to handle them. Types of Warnings The main types of warnings you will encounter are: Missing directories referenced in toc.yml files warning: Unable to find either toc.yml or toc.md inside xmpro-ai/. Make sure the file is included in config file docfx.json! Invalid file links in markdown files warning InvalidFileLink: Invalid file link:(~/docs/images/What_is_XMPro_Search_Light.png). Missing files referenced in toc.yml files Unable to find file \"collection.md\" for Href referenced by TOC file \"docs/concepts/toc.yml\" Why These Warnings Occur These warnings are normal during the migration process because: We're setting up the structure before all content is migrated We're creating placeholder files that reference other files that don't exist yet We're migrating the navigation structure before all content is available How to Handle These Warnings During the Migration Process During the migration process, you can safely ignore most of these warnings as they will be resolved as you progress through the migration steps. However, it's good practice to: Keep track of the warnings: Note which files and references are causing warnings so you can address them later Prioritize critical warnings: Focus on warnings that might affect the functionality of the site Address warnings incrementally: As you migrate each section, address the warnings related to that section Addressing Specific Warning Types Missing Directories For warnings about missing directories: Create the missing directory Create a placeholder toc.yml file in the directory Create a placeholder index.md file in the directory Example: mkdir docs-docfx/docs/xmpro-ai touch docs-docfx/docs/xmpro-ai/toc.yml touch docs-docfx/docs/xmpro-ai/index.md Invalid File Links For warnings about invalid file links: Create the missing images directory if it doesn't exist Copy the referenced images from the GitBook assets directory to the appropriate images directory Update the image references in the markdown files to use the correct paths Example: mkdir docs-docfx/docs/images Copy-Item docs-gitbook/docs/assets/What_is_XMPro_Search_Light.png -Destination docs-docfx/docs/images/ Missing Files Referenced in TOC For warnings about missing files referenced in toc.yml files: Create placeholder files for the missing files Update the toc.yml files to reference the correct paths Example: touch docs-docfx/docs/concepts/collection.md Using the Migration Helper Script The migration helper script (migration-helper.ps1) can help automate the process of addressing these warnings. Use the following commands: # Create directory structure .\\migration-helper.ps1 -GitBookPath \"C:\\Work\\Git\\public-docs-pages\\docs-gitbook\" -DocFXPath \"C:\\Work\\Git\\public-docs-pages\\docs-docfx\" -CreateStructure # Migrate images .\\migration-helper.ps1 -GitBookPath \"C:\\Work\\Git\\public-docs-pages\\docs-gitbook\" -DocFXPath \"C:\\Work\\Git\\public-docs-pages\\docs-docfx\" -MigrateImages Final Cleanup Once all content has been migrated, you should perform a final cleanup to address any remaining warnings: Run docfx build to get a list of all warnings Address each warning systematically Run docfx build again to verify that all warnings have been resolved Conclusion Warnings are a normal part of the migration process and should be addressed incrementally as you progress through the migration steps. By following the guidelines in this document, you can effectively manage and resolve these warnings to ensure a successful migration."
  },
  "migration-plan.html": {
    "href": "migration-plan.html",
    "title": "XMPro Documentation Migration Plan: GitBook to DocFX | XMPro",
    "summary": "XMPro Documentation Migration Plan: GitBook to DocFX This document outlines the plan for migrating the XMPro documentation from GitBook to DocFX. The migration will be done iteratively, with each step being completed and verified before moving on to the next step. Migration Overview The migration will follow these high-level steps: Set up the DocFX project structure Migrate the navigation structure Migrate core content pages Migrate images and other assets Implement styling and customization Verify links and functionality Deploy the migrated documentation Branching Strategy Each step of the migration will be done on a separate feature branch. This allows for: Isolated work on specific migration tasks Easy review of changes through pull requests Ability to roll back changes if needed Parallel work on different migration tasks The branch naming convention will be: migrate/[section-name]/[specific-task] For example: migrate/navigation/main-toc migrate/content/getting-started migrate/assets/images IMPORTANT: Always create a new branch for each migration task and commit your changes to that branch. Do not make changes directly to the main branch. Follow these steps for each migration task: Create a new branch for the task: git checkout -b migrate/[section-name]/[specific-task] Make your changes Add the changes to the staging area: git add . Commit the changes: git commit -m \"Descriptive message about the changes\" Push the changes to the remote repository: git push -u origin migrate/[section-name]/[specific-task] Create a pull request (via GitHub UI) After the PR is approved and merged, proceed to the next step Migration Steps Step 1: Set up the DocFX Project Structure Branch: migrate/setup/project-structure # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/setup/project-structure Create the basic DocFX project structure Configure docfx.json for the XMPro documentation Set up the initial toc.yml file Create placeholder files for key sections Verify the basic structure works by building and serving the site Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the basic structure is in place. Completion: # Commit changes git add . git commit -m \"Set up DocFX project structure\" git push -u origin migrate/setup/project-structure # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 2: Migrate the Main Navigation Structure Branch: migrate/navigation/main-toc # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/navigation/main-toc Analyze the GitBook SUMMARY.md file to understand the current navigation structure Create the main toc.yml file in the DocFX project Create section toc.yml files for each major section Verify the navigation structure works correctly Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the navigation structure matches the GitBook structure. Completion: # Commit changes git add . git commit -m \"Migrate main navigation structure\" git push -u origin migrate/navigation/main-toc # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 3: Migrate the Introduction and Getting Started Sections Branch: migrate/content/introduction-getting-started # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/introduction-getting-started Migrate the README.md file to introduction.md Migrate the Getting Started section pages Update links and references in these pages Create necessary images directory and migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Introduction and Getting Started sections display correctly. Completion: # Commit changes git add . git commit -m \"Migrate Introduction and Getting Started sections\" git push -u origin migrate/content/introduction-getting-started # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 4: Migrate the Concepts Section Branch: migrate/content/concepts # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/concepts Create the concepts directory structure Migrate the Concepts section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Concepts section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate Concepts section\" git push -u origin migrate/content/concepts # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 5: Migrate the How-Tos Section Branch: migrate/content/how-tos # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/how-tos Create the how-tos directory structure Migrate the How-Tos section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the How-Tos section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate How-Tos section\" git push -u origin migrate/content/how-tos # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 6: Migrate the Blocks-Toolbox Section Branch: migrate/content/blocks-toolbox # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/blocks-toolbox Create the blocks-toolbox directory structure Migrate the Blocks-Toolbox section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Blocks-Toolbox section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate Blocks-Toolbox section\" git push -u origin migrate/content/blocks-toolbox # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 7: Migrate the Administration Section Branch: migrate/content/administration # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/administration Create the administration directory structure Migrate the Administration section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Administration section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate Administration section\" git push -u origin migrate/content/administration # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 8: Migrate the Installation Section Branch: migrate/content/installation # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/installation Create the installation directory structure Migrate the Installation section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Installation section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate Installation section\" git push -u origin migrate/content/installation # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 9: Migrate the Release Notes Section Branch: migrate/content/release-notes # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/release-notes Create the release-notes directory structure Migrate the Release Notes section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Release Notes section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate Release Notes section\" git push -u origin migrate/content/release-notes # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 10: Migrate the Resources Section (Last Priority) Branch: migrate/content/resources # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/content/resources Create the resources directory structure Migrate the Resources section pages Update links and references in these pages Migrate images used in these pages Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the Resources section displays correctly. Completion: # Commit changes git add . git commit -m \"Migrate Resources section\" git push -u origin migrate/content/resources # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 11: Implement Styling and Customization Branch: migrate/styling/customization # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/styling/customization Customize the DocFX template to match XMPro branding Implement custom CSS for styling Configure the search functionality Add custom JavaScript for enhanced functionality Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the styling and customization match the desired look and feel. Completion: # Commit changes git add . git commit -m \"Implement styling and customization\" git push -u origin migrate/styling/customization # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 12: Verify Links and Functionality Branch: migrate/verification/links-functionality # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/verification/links-functionality Check all internal links to ensure they work correctly Verify external links are correct Test search functionality Test navigation functionality Verify images and other assets display correctly Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that all links and functionality work correctly. Completion: # Commit changes git add . git commit -m \"Verify links and functionality\" git push -u origin migrate/verification/links-functionality # Create pull request (via GitHub UI) # After PR is approved and merged, proceed to the next step Step 13: Final Review and Deployment Branch: migrate/deployment/final # Create and switch to the feature branch git checkout main git pull git checkout -b migrate/deployment/final Perform a final review of the migrated documentation Fix any remaining issues Verify the GitHub Actions workflow for automatic deployment Merge the final changes to the main branch to trigger deployment Verification: # Build and serve the site locally cd docs-docfx docfx build docfx serve _site Open a browser and navigate to http://localhost:8080 to verify that the documentation is ready for deployment. After merging to main, verify that the deployed documentation works correctly on GitHub Pages. Completion: # Commit changes git add . git commit -m \"Final review and deployment preparation\" git push -u origin migrate/deployment/final # Create pull request (via GitHub UI) # After PR is approved and merged, the site will be automatically deployed to GitHub Pages Continuous Deployment A GitHub Actions workflow has been set up to automatically deploy the documentation to GitHub Pages whenever changes are merged into the main branch. This ensures that each migration step is immediately visible on the public documentation site once it's completed and merged. The deployment workflow is defined in .github/workflows/deploy-docs.yml and performs the following steps: Checks out the repository Sets up .NET Installs DocFX Builds the DocFX documentation Deploys the built site to the gh-pages branch This means that after each migration step is completed and the feature branch is merged into main, the changes will be automatically deployed to GitHub Pages. This allows for incremental deployment of the documentation as the migration progresses. Content Migration Guidelines Markdown Conversion GitBook and DocFX both use Markdown, but there are some differences in syntax and features. Here are some guidelines for converting GitBook Markdown to DocFX Markdown: Hints/Callouts: Convert GitBook hints to DocFX alerts: GitBook: > [!NOTE] > This is a note DocFX: > [!NOTE] > This is a note Tabs: Convert GitBook tabs to DocFX tabs: GitBook: {% tabs %} {% tab title=\"Tab 1\" %} Content for Tab 1 {% endtab %} {% tab title=\"Tab 2\" %} Content for Tab 2 {% endtab %} {% endtabs %} DocFX: # [Tab 1](#tab/tab1) Content for Tab 1 # [Tab 2](#tab/tab2) Content for Tab 2 *** Code Blocks: Ensure code blocks use the correct syntax: GitBook: ```javascript const x = 5; DocFX: ```markdown ```javascript const x = 5; Images: Update image paths to use the correct relative paths: GitBook: ![Alt text](../assets/image.png) DocFX: ![Alt text](../images/image.png) Links: Update links to use the correct relative paths: GitBook: [Link text](../path/to/page.md) DocFX: [Link text](../path/to/page.md) Image Migration Create an images directory in each section directory Copy images from the GitBook assets directory to the appropriate images directory Update image references in the Markdown files to use the new paths Link Updates Update internal links to use the correct relative paths Verify external links are correct Update anchor links to use the correct format Migration Helper Script A PowerShell script (migration-helper.ps1) will be created to assist with the migration process. This script will: Create the necessary directory structure Convert GitBook Markdown to DocFX Markdown Update image and link references Generate toc.yml files from the GitBook SUMMARY.md file Progress Tracking A progress tracking document will be maintained to keep track of the migration progress. This document will include: A list of all pages to be migrated The status of each page (Not Started, In Progress, Completed) Any issues or notes for each page Handling DocFX Build Warnings During the migration process, you will encounter various warnings when building the DocFX project. These warnings are normal and expected, especially during the early stages of migration when not all content has been migrated yet. Types of Warnings The main types of warnings you will encounter are: Missing directories referenced in toc.yml files Invalid file links in markdown files Missing files referenced in toc.yml files Handling Warnings A detailed guide on handling DocFX build warnings is available in the handling-docfx-warnings.md document. This document explains: Why these warnings occur How to handle these warnings during the migration process Strategies for addressing specific warning types Using the migration helper script to resolve warnings Final cleanup process to address remaining warnings Warning Resolution Strategy The strategy for handling warnings during the migration process is: Ignore non-critical warnings during initial migration: Focus on migrating content first, then address warnings Address warnings incrementally: As you migrate each section, address the warnings related to that section Create placeholder files and directories: For missing files and directories referenced in toc.yml files Migrate images early: To resolve invalid image references Perform final cleanup: Once all content is migrated, address any remaining warnings By following this strategy, you can effectively manage and resolve warnings without getting bogged down in fixing every warning during the initial migration process. Conclusion This migration plan provides a structured approach to migrating the XMPro documentation from GitBook to DocFX. By following this plan, the migration can be done in a systematic and controlled manner, ensuring that the migrated documentation is accurate, complete, and functional. Each step should be completed and verified before moving on to the next step. This approach minimizes the risk of issues and ensures that the migration is done correctly. Remember that warnings are a normal part of the migration process and should be addressed incrementally as you progress through the migration steps. Don't let warnings block your progress, but also don't ignore them completely."
  }
}